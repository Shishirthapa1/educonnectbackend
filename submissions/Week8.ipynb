{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ArDymXmKV7U"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "# This is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder = keras.Model(input_img, encoded)"
      ],
      "metadata": {
        "id": "y2-5vtwrKkeV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "# Retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# Create the decoder model\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "metadata": {
        "id": "xc3rY3E_KjB0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "KzRQ0U3ZKrUx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYY8KlmsK0UU",
        "outputId": "79fd21ad-8515-4adf-f0ca-06ef3d3821ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RFRXF84K9nQ",
        "outputId": "ab960a16-70e8-4ad0-f7eb-577a4abd6585"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncGyH39pLDaV",
        "outputId": "22e92aae-b685-4f13-ef3d-eec936c26074"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 4s 13ms/step - loss: 0.2743 - val_loss: 0.1872\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.1701 - val_loss: 0.1543\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.1452 - val_loss: 0.1346\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.1291 - val_loss: 0.1215\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.1183 - val_loss: 0.1126\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1108 - val_loss: 0.1065\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.1056 - val_loss: 0.1022\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.1019 - val_loss: 0.0992\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0993 - val_loss: 0.0969\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0974 - val_loss: 0.0953\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0961 - val_loss: 0.0943\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0953 - val_loss: 0.0936\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0947 - val_loss: 0.0933\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0944 - val_loss: 0.0930\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0941 - val_loss: 0.0927\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0939 - val_loss: 0.0926\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0938 - val_loss: 0.0924\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0934 - val_loss: 0.0923\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0933 - val_loss: 0.0922\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0933 - val_loss: 0.0921\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0932 - val_loss: 0.0919\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0930 - val_loss: 0.0917\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0926 - val_loss: 0.0915\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8154539900>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR3HeJCpLK_O",
        "outputId": "2ac77187-66b6-4561-925a-2ae0a715f750"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # How many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "V9ZcFMl8LL7A",
        "outputId": "40fe71a1-4a76-4b63-a849-8310e8405700"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "\n",
        "encoding_dim = 32\n",
        "\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# Add a Dense layer with a L1 activity regularizer\n",
        "encoded = layers.Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "metadata": {
        "id": "l3mQVb-LLcUh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = keras.Input(shape=(784,))\n",
        "encoded = layers.Dense(128, activation='relu')(input_img)\n",
        "encoded = layers.Dense(64, activation='relu')(encoded)\n",
        "encoded = layers.Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = layers.Dense(64, activation='relu')(encoded)\n",
        "decoded = layers.Dense(128, activation='relu')(decoded)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(decoded)"
      ],
      "metadata": {
        "id": "WgxTIgqbLfBc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu_alsP-LiTC",
        "outputId": "d3f5923f-18de-4763-9e4c-40c9d3884bd0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 6s 22ms/step - loss: 0.2527 - val_loss: 0.1704\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1529 - val_loss: 0.1382\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1324 - val_loss: 0.1260\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.1248 - val_loss: 0.1204\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1197 - val_loss: 0.1159\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1153 - val_loss: 0.1116\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.1118 - val_loss: 0.1090\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1090 - val_loss: 0.1064\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1068 - val_loss: 0.1049\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.1046 - val_loss: 0.1023\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1027 - val_loss: 0.1005\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.1010 - val_loss: 0.0992\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0996 - val_loss: 0.0977\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0985 - val_loss: 0.0970\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0976 - val_loss: 0.0960\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0967 - val_loss: 0.0951\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0957 - val_loss: 0.0943\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0948 - val_loss: 0.0937\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0939 - val_loss: 0.0927\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0920 - val_loss: 0.0920\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0915 - val_loss: 0.0904\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0910 - val_loss: 0.0900\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0906 - val_loss: 0.0898\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0902 - val_loss: 0.0897\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0898 - val_loss: 0.0891\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0894 - val_loss: 0.0888\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0891 - val_loss: 0.0883\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0889 - val_loss: 0.0881\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0886 - val_loss: 0.0879\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0883 - val_loss: 0.0877\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0881 - val_loss: 0.0872\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0879 - val_loss: 0.0875\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0877 - val_loss: 0.0869\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0875 - val_loss: 0.0868\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0873 - val_loss: 0.0866\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0871 - val_loss: 0.0865\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0869 - val_loss: 0.0863\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0867 - val_loss: 0.0861\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0865 - val_loss: 0.0859\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0864 - val_loss: 0.0857\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0862 - val_loss: 0.0855\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0861 - val_loss: 0.0854\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0859 - val_loss: 0.0854\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0858 - val_loss: 0.0855\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0857 - val_loss: 0.0854\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0856 - val_loss: 0.0853\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0855 - val_loss: 0.0849\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0853 - val_loss: 0.0851\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0853 - val_loss: 0.0852\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0852 - val_loss: 0.0846\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0851 - val_loss: 0.0844\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0850 - val_loss: 0.0844\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0849 - val_loss: 0.0843\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0848 - val_loss: 0.0845\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0848 - val_loss: 0.0843\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0847 - val_loss: 0.0843\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0846 - val_loss: 0.0842\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0845 - val_loss: 0.0842\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0844 - val_loss: 0.0839\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0844 - val_loss: 0.0840\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0843 - val_loss: 0.0840\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0842 - val_loss: 0.0838\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0841 - val_loss: 0.0837\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0841 - val_loss: 0.0840\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0840 - val_loss: 0.0836\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0840 - val_loss: 0.0838\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0839 - val_loss: 0.0838\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0838 - val_loss: 0.0836\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0838 - val_loss: 0.0837\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0838 - val_loss: 0.0837\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0837 - val_loss: 0.0836\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0837 - val_loss: 0.0835\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0836 - val_loss: 0.0835\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0835 - val_loss: 0.0834\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0836 - val_loss: 0.0835\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0835 - val_loss: 0.0833\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0835 - val_loss: 0.0831\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0834 - val_loss: 0.0832\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0834 - val_loss: 0.0830\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0834 - val_loss: 0.0830\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0833 - val_loss: 0.0831\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0833 - val_loss: 0.0831\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0833 - val_loss: 0.0830\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0832 - val_loss: 0.0829\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0832 - val_loss: 0.0828\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0831 - val_loss: 0.0830\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0831 - val_loss: 0.0829\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0831 - val_loss: 0.0828\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0830 - val_loss: 0.0828\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.0830 - val_loss: 0.0831\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0830 - val_loss: 0.0827\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0829 - val_loss: 0.0828\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0829 - val_loss: 0.0827\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0829 - val_loss: 0.0825\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0829 - val_loss: 0.0827\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0829 - val_loss: 0.0828\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0828 - val_loss: 0.0828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f814fa17190>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "o_Y8dkDsM3mO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
      ],
      "metadata": {
        "id": "i-ApxQTCM9WN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfWM1fo6M_Xw",
        "outputId": "c2244bf3-9b97-4daf-ad6c-2a5fb28777bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 78s 162ms/step - loss: 0.2049 - val_loss: 0.1484\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 92s 195ms/step - loss: 0.1383 - val_loss: 0.1297\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 82s 175ms/step - loss: 0.1263 - val_loss: 0.1206\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 80s 170ms/step - loss: 0.1191 - val_loss: 0.1156\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 78s 166ms/step - loss: 0.1148 - val_loss: 0.1118\n",
            "Epoch 6/50\n",
            "416/469 [=========================>....] - ETA: 8s - loss: 0.1119"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n + 1):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LIhJSUvWOfJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = keras.Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape((4, 4 * 8)).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lzsO67baOhmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "H5XuiMOCOkQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pv4S_lelOnO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# At this point the representation is (7, 7, 32)\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "eJQnOS8kOuoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
      ],
      "metadata": {
        "id": "ihLGbwL3OxFC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}